{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e361100",
   "metadata": {},
   "source": [
    "## Example: Joint inference of $p(G, \\Theta | \\mathcal{D})$ for Gaussian Bayes nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d0dfc",
   "metadata": {},
   "source": [
    "Setup for Google Colab. Selecting the **GPU** runtime available in Google colab will make inference significantly faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/larslorch/dibs.git\n",
    "%cd dibs\n",
    "%pip install -e . --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b52aa",
   "metadata": {},
   "source": [
    "DiBS translates the task of inferring the posterior over Bayesian networks into an inference problem over the continuous latent variable $Z$. This is achieved by modeling the directed acyclic graph $G$ of the Bayesian network using the generative model $p(G | Z)$. The prior $p(Z)$ enforces the acyclicity of $G$.\n",
    "Ultimately, this allows us to infer $p(G, \\Theta | \\mathcal{D})$ (and $p(G | \\mathcal{D})$) using off-the-shelf inference methods such as Stein Variational gradient descent (SVGD) (Liu and Wang, 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8370c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random as random\n",
    "\n",
    "key = random.PRNGKey(123)\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da5e4a",
   "metadata": {},
   "source": [
    "### Generate synthetic ground truth Bayesian network and BN model for inference\n",
    "\n",
    "`data` contains information about and observations sampled from a synthetic, ground truth causal model with `n_vars` variables. By default, the conditional distributions are linear Gaussian. The random graph model is set by `graph_prior_str`, where `er` denotes Erdos-Renyi and `sf` scale-free graphs. \n",
    "\n",
    "`model` defines prior $p(G, \\Theta)$ and likelihood $p(x | G, \\Theta)$ of the BN model for which DiBS will infer the posterior.\n",
    "\n",
    "**For posterior inference of nonlinear Gaussian networks parameterized by fully-connected neural networks, use the function `make_nonlinear_gaussian_model`.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98551a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dibs.target import make_linear_gaussian_model, make_nonlinear_gaussian_model\n",
    "from dibs.utils import visualize_ground_truth\n",
    "\n",
    "key, subk = random.split(key)\n",
    "data, model = make_linear_gaussian_model(key=subk, n_vars=20, graph_prior_str=\"sf\")\n",
    "\n",
    "visualize_ground_truth(data.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08e46b",
   "metadata": {},
   "source": [
    "### DiBS with SVGD\n",
    "\n",
    "Infer $p(G, \\Theta | D)$ under the prior and conditional distributions defined by `model`.\n",
    "The below visualization shows the *matrix of edge probabilities* $G_\\alpha(Z^{(k)})$ implied by each transported latent particle (i.e., sample) $Z^{(k)}$ during the iterations of SVGD with DiBS. Refer to the paper for further details.\n",
    "\n",
    "To explicitly perform posterior inference of $p(G | \\mathcal{D})$ using a closed-form marginal likelihood $p(D | G)$, use the separate, analogous class `MarginalDiBS` as demonstrated in the example notebook `dibs_marginal.ipynb`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0ece4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dibs.inference import JointDiBS\n",
    "\n",
    "dibs = JointDiBS(x=data.x, inference_model=model)\n",
    "key, subk = random.split(key)\n",
    "gs, thetas = dibs.sample(key=subk, n_particles=20, steps=1000, callback_every=50, callback=dibs.visualize_callback())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41dc8cc",
   "metadata": {},
   "source": [
    "### Evaluate on held-out data\n",
    "\n",
    "Form the empirical (i.e., weighted by counts) and mixture distributions (i.e., weighted by unnormalized posterior probabilities, denoted DiBS+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dibs_empirical = dibs.get_empirical(gs, thetas)\n",
    "dibs_mixture = dibs.get_mixture(gs, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e275383",
   "metadata": {},
   "source": [
    "Compute some evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3dc2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dibs.metrics import expected_shd, threshold_metrics, neg_ave_log_likelihood\n",
    "\n",
    "for descr, dist in [('DiBS ', dibs_empirical), ('DiBS+', dibs_mixture)]:\n",
    "    \n",
    "    eshd = expected_shd(dist=dist, g=data.g)        \n",
    "    auroc = threshold_metrics(dist=dist, g=data.g)['roc_auc']\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=dibs.eltwise_log_likelihood, x=data.x_ho)\n",
    "    \n",
    "    print(f'{descr} |  E-SHD: {eshd:4.1f}    AUROC: {auroc:5.2f}    neg. LL {negll:5.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6bdf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
